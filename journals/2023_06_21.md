- #protoflow/work
	- i had an acid trip yesterday and I came out of it with more clarity that I need to write a document explicitly defining what protoflow is because it is not a product that I can sell it is a tool. I need to talk with more people to understand what the product for protoflow could look like (ex. managed instance, license, support, etc.) I realized that talking with Zapier could help a lot in figuring out what the product could be since they are protoflow but for bizdev. It would be really cool if I could find some smaller contracts with people to build capabilities for them using protoflow, but I will need to start reaching out through the network to find those connections.
	- at the very least, I am closing in on being able to build actual applications with lunabrain using protoflow which I think could be the "oh shit" demo that I have been wanting to build
	- now that I have the type generating pretty well written, I can go back to integrating the reactive programming ideas we talked about into the workflow
	- protoflow registry
		- instead of duplicating types into individual protobuf files, the types should probably come from a registry?
	- there seem to be some problems when trying to edit a protobuf file in place
		- input and output types want to import the file that they came from
			- should be able to replace the package
		- the protobuf file is trying to import itself?
	- RFC draft
		- **# Protoflow: Workflow Orchestration Platform for Connecting gRPC Methods
		- ## Introduction
		- The purpose of this RFC is to propose a workflow orchestration platform that enables the connection of gRPC methods in order to facilitate the efficient movement of data. The platform aims to handle free-formed data, data with loose or rigid schemas (JSON and Protocol Buffers), and composable functions that transform data. It also provides abstractions for various types of resources such as language services, blobs, docstores, RDS, and pub/sub. The platform will support development, staging, and production environments, with a preference for Kubernetes in production.
		- ## Motivation
		- Managing the flow of data and orchestrating complex workflows across distributed systems is a common challenge in modern software development. By providing a standardized platform for connecting gRPC methods and composing workflows, we can simplify the development, deployment, and management of data-driven applications.
		- ### Background
		- Protobuf types represent a simple, yet expressive way to represent data. The specification has had decades (introduced in 2001) of refinement by Google and the later introduction of gRPC, building on the powerful type primitives Protobuf provides. While many large tech-first companies have adopted Protobuf and gRPC internally, the widespread use of this technology is not seen. Possible explanations for this could be the lack of consistent tooling between languages, perceived complexity of learning a new type system, or simply not enough educational material for adopting the technology.
		- One of the significant benefits of using gRPC over REST is the inherent support for static typing provided by compiling protobuf types in each language. Unlike REST, which typically relies on JSON for data serialization, gRPC utilizes protobufs as its default serialization format. The process of compiling protobuf schemas generates strongly typed code in multiple programming languages, enabling developers to leverage the advantages of static typing. This ensures better type safety, early detection of potential errors, and improved code reliability, as the compiler can catch type-related issues during development. By embracing static typing, gRPC empowers developers to write robust and maintainable code, leading to reduced bugs and enhanced productivity in the long run.
		- gRPC is as close as we have come to having LEGOs as code. By not having focus on a market outside of the needs of large technology companies, it has been unable to make a meaningful impact for smaller
		- ## Goals
		- -
		- Enable seamless connection of gRPC methods to facilitate data movement.
		- -
		- Support free-formed data and data with loose or rigid schemas (JSON and Protocol Buffers).
		- -
		- Provide a composable function capability to transform data.
		- -
		- Offer abstractions for various types of resources, such as language services, blobs, docstores, RDS, and pub/sub.
		- -
		- Support development, staging, and production environments.
		- -
		- Encourage efficient local development by minimizing the reliance on virtualization.
		- -
		- Leverage existing tools and frameworks for deployment (e.g., Tilt) and production (e.g., Kubernetes).
		- ## Workflow Composition
		- The proposed platform enables the composition of workflows by connecting a resource's functions together. Workflows dictate the movement and transformation of data, allowing it to flow in a desirable manner. This is achieved by defining a sequence of gRPC method calls and applying composable functions to transform the data as it moves through the workflow.![](https://lh3.googleusercontent.com/Fjp-5xEbvxVFY72ALqWNIt7KAJBgr0WdehDj3vFu8l5dgjpOTED2QNwdGt2gvYq2s8dUZrspA-4GMRoJ0tPnFQ47B_w0PVym5vzblMM4V7RLjoYbM9yDNzDRl30EpXEDRv1KNdH8GSC9jVBdyXWknN4)
		- ### Runtime
		- The runtime which conducts the workflow must be able to run as a single binary to support local development, but also scale horizontally for production.
		- ### Scalability
		- Uber was able to scale its real time workflows by developing [Cadence](https://www.uber.com/blog/open-source-orchestration-tool-cadence-overview/). The team has since left Uber to form [Temporal](https://temporal.io/). This framework will be essential for achieving a larger scale.
		- ## Data Handling
		- The platform supports multiple types of data, including free-formed data and data with loose or rigid schemas. JSON is the recommended format for free-formed data, while Protocol Buffers (protobuf) are used for data with a rigid schema. The platform should provide mechanisms for data serialization, deserialization, validation, and schema evolution.
		- ### Reactive Programming
		- By leveraging reactive programming paradigms, the platform can handle data streams and asynchronous events in a highly efficient and responsive manner. Reactive streams and event-driven architectures will be utilized to process incoming data, allowing for real-time data transformations and seamless integration with external systems. The platform will provide reactive libraries and abstractions to handle data flows, event-driven triggers, and reactive operators for data manipulation. This approach ensures that the platform can efficiently handle large volumes of data, respond to changes in real-time, and adapt to dynamic workflow requirements, providing a highly flexible and scalable data handling solution.
		- An example library that provides a number of such primitives is [RxGo](https://github.com/reactivex/rxgo).
		- ## Composable Functions
		- Composable functions play a crucial role in the platform by transforming data from one format to another. These functions are written in the supported programming language and operate on the data received from gRPC methods. They should be easily reusable and composable, allowing for complex data transformations within workflows.
		- The proposed system aims to adhere to the principles of the [12-factor app](https://12factor.net/), which provide guidelines for building scalable and maintainable software. Here is a list of how the system addresses each principle:
		- -
		- **Codebase**: The system treats the codebase as a single entity, utilizing version control systems like Git to manage code changes. It encourages a modular approach to code organization, allowing for independent deployment and scaling of individual components.
		- -
		- **Dependencies**: The system utilizes package management tools to explicitly declare and manage dependencies. It ensures that all dependencies are isolated and packaged with the application, avoiding conflicts and providing consistent environments across deployments.
		- -
		- **Config**: Configuration is stored in environment variables, allowing for easy and flexible configuration changes without modifying the codebase. The system supports runtime configuration, enabling dynamic adjustment of settings during operation.
		- -
		- **Backing Services**: The system provides resource abstractions for various backing services such as databases, pub/sub systems, and storage. These abstractions encapsulate the necessary code and configuration, allowing for easy switching between different providers or implementations.
		- -
		- **Build, Release, Run**: The system separates the build, release, and run stages. It supports build tools and scripts for compiling code and creating executable artifacts. Release management is handled through deployment configurations that define the runtime environment and dependencies. The platform orchestrates the running of components within a production environment.
		- -
		- **Processes**: The system follows a process-oriented architecture, with each component running as a separate process or container. It utilizes process isolation mechanisms provided by the underlying infrastructure (e.g., containers) to ensure robustness and scalability.
		- -
		- **Port Binding**: The system adheres to the principle of port binding, allowing individual components to bind to assigned ports dynamically. It utilizes service discovery mechanisms (e.g., Kubernetes service discovery) to route requests to the appropriate components.
		- -
		- **Concurrency**: The system is designed to support concurrency and parallelism. It leverages scalable infrastructure (such as Kubernetes) to distribute workload across multiple instances or nodes, allowing for efficient resource utilization and improved performance.
		- -
		- **Disposability**: The system embraces the concept of disposability, enabling easy startup and shutdown of components. It utilizes containerization technology to provide lightweight and isolated runtime environments, allowing for rapid scaling and graceful recovery in case of failures.
		- -
		- **Dev/Prod Parity**: The system promotes parity between development and production environments. It provides tools and configurations for local development that closely resemble the production environment, ensuring consistent behavior and minimizing deployment-related issues. Resource abstraction allows for localized mocking.
		- -
		- **Logs**: The system encourages proper logging practices, generating logs as event streams and treating them as valuable event data. It supports structured logging and integrates with existing logging frameworks and tools for centralized log management and analysis.
		- -
		- **Admin Processes**: The system provides administrative interfaces and processes to manage and monitor the platform. It supports health checks, performance monitoring, and management endpoints to enable effective monitoring, troubleshooting, and maintenance of the system.
		- ## Resource Abstractions
		- To interact with external resources, the platform provides abstractions for common resource types. These abstractions encapsulate the necessary code and configuration required to connect and interact with resources such as language services, blobs, docstores, RDS (Relational Database Service), and pub/sub systems. The platform should leverage the Go [Cloud Development Kit](http://gocloud.dev) for consistent and portable resource abstractions.
		- ## Development Environment
		- Efficient local development is a priority for the platform. To minimize the reliance on virtualization, the platform recommends using binaries and scripts that can be executed directly on the local development machine. Additionally, a docker-compose configuration should be provided to set up a local development environment with all necessary dependencies.
		- ## Deployment
		- For streamlined deployment, the platform suggests using Tilt (tilt.dev). Tilt enables fast and efficient local development by automatically rebuilding and deploying changes as they are made. It provides a live feedback loop for developers, simplifying the deployment and testing process.
		- ## Production Environment
		- In the production environment, the platform encourages the use of Kubernetes for container orchestration. Kubernetes offers robust scalability, high availability, and declarative configuration management, making it an ideal choice for hosting and managing the platform's components and workflows. The platform should provide clear guidelines and documentation for deploying and managing the platform on Kubernetes.
		- **
		- https://docs.google.com/document/d/1T2oXT8hn8teHTqUMksfTCQojD1RGg4IjYqxkRvK7zoU/edit