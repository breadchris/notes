- fake real camera #blender {{video https://youtu.be/YE9rEQAGpLw}}
- https://github.com/akutruff/typescript-needs-types #js
- #lunabrain/work
	- #blog/ideas An important thing to consider here is that your milage will vary with vector database not just depending on the data that you are storing, but also what "data" is going to be used for retreiving content. Semantic search is looking for semantic similarities and if you are storing answers (Paris is in France) they might look different, or not semantically similar, than the question being asked (What country is Paris in?). The question might look more like other questions (What country is Berlin in?) rather than the actual content you are interested in finding. There is a great explaination of this stuff on llama index's docs page [https://gpt-index.readthedocs.io/en/latest/how_to/query_engine/advanced/query_transformations.html#hyde-hypothetical-document-embeddings](https://gpt-index.readthedocs.io/en/latest/how_to/query_engine/advanced/query_transformations.html#hyde-hypothetical-document-embeddings). I would recommend checking out this project, they are pretty good. Much better reference/tool than langchain for what you are looking at imo.