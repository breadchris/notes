- #js/projects https://github.com/NangoHQ/nango #saas/integrations
- #lunabrain/work
	- lunabrain openai prompting code #code/extra ```go
	  func (c *OpenAIQAClient) runPromptOverContent(
	  	respSize int,
	  	prompt string,
	  	content string,
	  ) ([]string, error) {
	  	var (
	  		responses []string
	  	)
	  	promptMsg := openai.ChatCompletionMessage{
	  		Role:    "system",
	  		Content: prompt,
	  	}
	  	baseTokenCount := respSize
	  	promptTc, err := tokenCountForMessage(promptMsg, c.modelDetails)
	  	if err != nil {
	  		return nil, errors.Wrapf(err, "failed to encode prompt data")
	  	}
	  	baseTokenCount += promptTc
	  
	  	msgTokens, err := tokenCountForMessage(openai.ChatCompletionMessage{
	  		Role: openai.ChatMessageRoleUser,
	  	}, c.modelDetails)
	  	if err != nil {
	  		return nil, errors.Wrapf(err, "failed to encode empty data")
	  	}
	  
	  	tc, err := tokenCountForMessage(openai.ChatCompletionMessage{
	  		Role:    openai.ChatMessageRoleUser,
	  		Content: content,
	  	}, c.modelDetails)
	  	if err != nil {
	  		return nil, errors.Wrapf(err, "failed to encode prompt data")
	  	}
	  	contentTc := tc - msgTokens
	  
	  	perPrompt := c.modelDetails.MaxTokens - baseTokenCount
	  	chunkCount := contentTc / perPrompt
	  
	  	chunker, err := NewChunker()
	  	if err != nil {
	  		return nil, errors.Wrapf(err, "failed to create chunker")
	  	}
	  
	  	chunks, err := chunker.SplitText(content, chunkCount)
	  	if err != nil {
	  		return nil, errors.Wrapf(err, "failed to split text")
	  	}
	  
	  	for _, chunk := range chunks {
	  		chatChunk := openai.ChatCompletionMessage{
	  			Role:    openai.ChatMessageRoleUser,
	  			Content: chunk,
	  		}
	  		chatTc, err := tokenCountForMessage(chatChunk, c.modelDetails)
	  		if err != nil {
	  			return nil, errors.Wrapf(err, "failed to encode prompt data")
	  		}
	  		r, err := c.Ask(chatTc+promptTc, []openai.ChatCompletionMessage{
	  			chatChunk,
	  			promptMsg,
	  		})
	  		if err != nil {
	  			return nil, errors.Wrapf(err, "failed to ask")
	  		}
	  		responses = append(responses, r)
	  	}
	  	return responses, nil
	  }
	  ```
		- ```
		  func tokenCountForMessage(msg openai.ChatCompletionMessage, modelDetails ModelDetails) (int, error) {
		    encoder, err := tokenizer.NewEncoder()
		    if err != nil {
		       return 0, err
		    }
		  - numTokens := 0
		    numTokens += modelDetails.TokensPerMsg
		    encoded, err := encoder.Encode(msg.Content)
		    if err != nil {
		       return 0, err
		    }
		    numTokens += len(encoded)
		    role, err := encoder.Encode(msg.Role)
		    if err != nil {
		       return 0, err
		    }
		    numTokens += len(role)
		    name, err := encoder.Encode(msg.Name)
		    if err != nil {
		       return 0, err
		    }
		    numTokens += len(name)
		    if msg.Name != "" {
		       numTokens += modelDetails.TokensPerName
		    }
		    numTokens += *promptTokenCount
		  *    return numTokens, nil
		  }
		  ```
		-