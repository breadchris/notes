- https://github.com/goldeneggg/structil #protoflow/design #golang/libraries
- turn sqlite database into graqphl server https://docs.wundergraph.com/docs/wundergraph-config-ts-reference/configure-sqlite-data-source
- #bass/tabs https://www.youtube.com/watch?v=bbvLpy7zoJY Still feel like your man
- #ml/gpt https://github.com/Torantulino/Auto-GPT still not sure what this is
- #cookwherever/ideas https://archive.org/download/CHOW-20220318162922-crawl900 #chowhound crawl
- #lunabrain/work ideas sent to Free
	- [https://docs.haystack.deepset.ai/docs/intro#1-nodes](https://docs.haystack.deepset.ai/docs/intro#1-nodes)
	- the way that they have chosen to approach the ML space is through these pluggable pipelines so you can use different techniques for your different ML requirements
	- so, very much Refinery lol
	- what I have been learning is that applying ML to a space where you can derive value means that you need to 1) collect data reliably 2) normalize the data (context specific, ex. chat messages, blog posts, Jira tasks) 3) transform the data (ex. summarize, categorize) 4) index the data for discovery (ex. similarity search, llm search, ranked text like bm25, fuzzy match)
	- there are some easy techniques that you can use that will get you a good bang for your buck, but you are also trying to prioritize speed of search vs accuracy of results
	- the reason I am interested in writing the vector search blog post is that there are a lot of things that we can speak to that people just simply don't know about when it comes to accuracy of results
	- you can make a vector search pretty fast, but the results are basically gibberish
	- without understanding how your data is clustered, your search is going to be pretty bad
	- TL;DR there are a lot of techniques that are not state of the art, which are tried and true that will significantly help the quality of results you get from using a LLM, and there is very little coherent information about what you should use and when
	- since this space is developing so rapidly
-